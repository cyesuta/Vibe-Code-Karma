# The Reality of LLMs: From Myth to Actuality

## Media Hype vs. Technical Reality

Every day, the media buzzes about AI replacing someone. Are Large Language Models (LLMs) really that miraculous?

Not quite. At their core, LLMs are systems that generate content sequentially based on patterns from vast amounts of existing data. They still face many insurmountable developmental challenges (as of August 2025).

## Yann LeCun's Perspective: The Four Challenges for AGI

Recently, Meta's Yann LeCun stated he is no longer interested in the further evolution of LLMs. He suggested that for AI to progress towards AGI, it must tackle four key areas:

1.  Enable AI to understand the physical world.
2.  Equip them with memory.
3.  Give them the ability to reason.
4.  Provide them with the capacity to plan.

Indeed, while the current race is in AI Agents, the competition still largely revolves around the large models themselves.

## A Deep Dive into the Four Challenges

### 1. Understanding the Physical World

LeCun's own team is building spaces in the virtual world. Others, like Google, are pushing forward with multimodal spatial recognition and statistics.

However, I feel that AI is still confined to the computer. There are too few vehicles—be it furniture, robots, or other mediums—that can interact with the physical world daily. Even depth cameras are currently standard only on pro-level iPhones and iPads. Once these become widespread, understanding the physical world could happen in an instant. The same applies to physical common sense.

### 2. Possessing Memory

From an application standpoint, memory is what the general public most needs from AI right now. Whether for training assistants, customer service, or for updating and self-learning, memory is essential. At the most basic level, it's awkward when an LLM can't keep up with the context of a conversation in a simple web chatbox after a short while.

Untrained human memory isn't very logical. Each event and piece of knowledge is stored like a tagged item in a memory palace, with connections established between them (the principle behind tools like Obsidian, which aims to aid human memory and knowledge organization). When we retrieve these memories, we can do so through abstract or fuzzy matching.

While the vector databases created by current knowledge base systems (RAG) follow this concept, their matching efficiency is poor if the retrieval hooks aren't well-defined during data ingestion. Not to mention the complexities of long-term vs. short-term memory, or memory driven by priority, emotion, or senses. It's incredibly complex. If an AI could truly mimic these, it would already have a personality, wouldn't it? XD.

As a second-best option, could classifying and storing information according to human-defined standards meet the high-frequency demands of tasks like customer service in the near future?

### 3. Reasoning Ability

Although various LLMs have produced reports over the past six months that appear to be the result of "logical thinking" through methods like DeepThink, DeepSearch, and DeepResearch, they are, in fact, still applying the LLM's underlying summarization and rule-based symbolic reasoning. They combine this with search and web crawling to simulate reasoning functions using vast amounts of data and articles.

However, this is still a long way from human judgment, which can be based on highly abstract conditions, analogies from existing knowledge, or common sense.

### 4. Planning Ability

This is similar to what I was thinking about a few days ago: if I were to plan an n8n workflow for someone with no computer skills, I should start from the conclusion and work backward—a results-oriented approach. For instance, when I ask an LLM to create an n8n workflow from my rough conceptual diagram, the process is never entirely satisfactory.

Current LLMs do not yet understand result-oriented or goal-oriented approaches, which makes it difficult for them to assist in planning. Most of their "planning" is based on summarizing what has been learned, rather than making judgments based on the current situation and goals. Current research is heading towards action sequencing and predicting the consequences of actions based on extensive learning summaries.

## Parallels with Human Development

I find this fascinating because these points mirror the progressive stages of human development:

1.  **Understanding the Physical World**: As we are born and grow, we naturally grasp basic common sense and physics. We understand our position in space, feel the wind and light, and perceive perspective changes with our eyes.
2.  **Memory System**: Next, we each develop our own unique memory systems and abilities, yet we all possess at least long-term and short-term memory, all centered around a "self" axis.
3.  **Higher Cognition**: Then comes reasoning and planning. Even for humans, these are relatively advanced "functions," and only a minority of people truly master them.

## Conclusion

LLMs have indeed brought about revolutionary changes, but there is still a long road ahead to true AGI. Understanding these limitations allows us to better utilize existing AI tools, leveraging their strengths in the areas where they excel, rather than blindly expecting them to be omnipotent.
