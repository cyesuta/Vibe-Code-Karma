# RAG建製指南（中集）：檢索與生成

## 🔍 檢索方式

### 檢索的兩大派別：關鍵字 vs. 語意

資訊檢索領域存在兩大互補派別：**關鍵字檢索**（如BM25、TF-IDF）專注於嚴格的字詞匹配，透過統計學方法計算分數，擅長精準命中特定關鍵字如 `PostgreSQL v15.3`，但無法理解語意，將「車子」和「汽車」視為無關詞彙。**向量檢索**（如FAISS、HNSW、IVFFlat）則理解文字意思，將查詢和文件轉換成向量在語意空間中比較，能處理同義詞問題，但對具體罕見關鍵字如產品型號 `NVDA-H100`不夠敏感。兩者形成完美互補關係。

正因為它們的優缺點剛好互補，我們在之後會使用 **Hybrid Search (混合式搜尋)** 這種當前最先進的策略之一 —— **同時**用向量檢索去理解您的問題「意思」，**又同時**用 BM25 去抓住您問題中的「關鍵字」，最後將兩邊的結果融合，確保既能理解您的意圖，又不會錯過任何關鍵細節。

### 向量檢索的兩種策略

向量檢索有兩種基本策略：**精確檢索**計算查詢向量與每個向量的真實距離，保證100%準確但速度極慢(O(n)複雜度)；**ANN檢索**使用演算法近似找到最相似結果，犧牲少許準確性換取巨大速度提升，能處理大規模資料但可能錯過最佳答案。在實際應用中，**資料分類策略+ANN搜索**是黃金組合，透過縮小搜索範圍和排除語意噪音，提升ANN在純淨環境下的準確性，讓RAG系統答案更精確可靠。

### 向量索引方法的選擇策略

**IndexFlatIP（Flat）** 提供 100% 準確性但查詢極慢，適合小規模資料集(<5萬筆)和基準測試。**IVFFlat** 採用分區策略平衡記憶體與速度，適合記憶體受限和百萬級資料。**HNSW** 是速度準確率綜合表現最佳的索引，適合即時系統但記憶體消耗大。**FAISS** 是靈活的檢索庫，支援多種索引和GPU加速，適合超大規模部署。

選擇原則：追求準確性選Flat，記憶體有限選IVFFlat，需要極速選HNSW，要靈活性選FAISS。

### 六種檢索方法的全面對比

| 檢索方法 (類型)                                                               | 核心原理與應用場景                                                                                                                                                                                             | 主要優劣分析                                                                                                                                                     | 實現難度與成本                                                                                                                                              |
| ----------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **BM25** `<br>`(關鍵字檢索)                                           | 基於詞頻和逆文件頻率的概率排序函數，透過統計學方法計算分數，擅長精確關鍵字查詢、產品型號搜索、法條檢索、文檔排序等需要精準匹配的場景                                                                           | ✅**搭配優勢**: 分數分布精細融合效果佳、業界標準生態成熟、精準匹配關鍵字速度極快 `<br>`❌ **搭配劣勢**: 需要雙重索引系統、無語意理解無法處理同義詞 | **實現**: 極低 (無需訓練)`<br>`**建構**: 極低 `<br>`**查詢**: 極低 `<br>`**記憶體**: 低                                       |
| **TF-IDF** `<br>`(關鍵字檢索)                                         | 詞頻-逆文件頻率統計權重計算，評估詞彙在文檔集合中的重要性，主要用於文檔分類、資訊檢索、特徵提取、基準比較等基礎分析工作                                                                                        | ✅**搭配優勢**: 實現簡單資源消耗低、計算快速廣泛支援 `<br>`❌ **搭配劣勢**: 分數分布粗糙融合效果差、現代系統支持有限、無法理解語意                 | **實現**: 極低 (經典演算法)`<br>`**建構**: 極低 `<br>`**查詢**: 極低 `<br>`**記憶體**: 低                                     |
| **IndexFlatIP (或 Flat)**`<br>`(向量檢索-精確檢索)                    | 100%準確的精確檢索方法，計算查詢向量與資料庫中每一個向量的真實距離，不做任何近似，進行暴力窮舉搜索。適合小規模資料集(< 5萬筆)的驗證、作為其他索引準確度的「黃金標準」比較、學術研究、原型開發                  | ✅**搭配優勢**: 作為準確度基準標準、100%準確結果可靠 `<br>`❌ **搭配劣勢**: 無法應用於生產環境只適合小規模測試、查詢極慢不適合大規模應用           | **實現**: 極低 (暴力搜索)`<br>`**建構**: 極低 `<br>`**查詢**: 極高 `<br>`**記憶體**: 低                                       |
| **IVFFlat (Inverted File Flat)**`<br>`(向量檢索-ANN檢索)              | 分而治之的索引策略，採用倒排檔案結構，將所有向量分成nlist個群組/分區，查詢時只搜索最可能包含答案的nprobe個分區，實現速度與記憶體佔用的良好平衡。適合記憶體受限環境、百萬到數億級數據、離線批處理、成本敏感應用 | ✅**搭配優勢**: 記憶體效率高成本控制佳、適合大規模數據處理、速度與記憶體平衡良好 `<br>`❌ **搭配劣勢**: 準確率略低於HNSW、邊界向量可能遺漏影響精度 | **實現**: 中等 (需調校 `nlist`、`nprobe`)`<br>`**建構**: 中等 `<br>`**查詢**: 中等 `<br>`**記憶體**: 低                   |
| **HNSW (Hierarchical Navigable Small World)**`<br>`(向量檢索-ANN檢索) | 目前公認在速度和準確率上綜合表現最好的索引類型，建立類似「高速公路網路」的多層圖結構，可以極快地在向量空間中導航到最相似的鄰近點。特別適合即時問答系統、推薦系統、大規模線上服務、低延遲要求等場景             | ✅**搭配優勢**: 查詢速度極快用戶體驗佳、準確率高結果質量穩定、速度準確率綜合表現最佳 `<br>`❌ **搭配劣勢**: 記憶體成本較高、參數調校複雜需精細調整 | **實現**: 高 (需調校 `M`、`ef_construction`、`ef_search`)`<br>`**建構**: 中等 `<br>`**查詢**: 極低 `<br>`**記憶體**: 高 |
| **FAISS** `<br>`(向量檢索庫)                                          | Facebook開源的高效相似性搜索庫，支援多種索引類型和GPU加速，提供豐富的索引選擇、高度優化、工業級穩定。主要用於大規模向量檢索、需要GPU加速、多種索引策略、生產級部署等企業級應用                                 | ✅**搭配優勢**: 支援多種索引類型靈活性高、GPU加速處理能力強、豐富索引選擇工業級穩定 `<br>`❌ **搭配劣勢**: 學習成本高集成複雜、配置複雜依賴較重    | **實現**: 中到高 (需熟悉不同索引類型)`<br>`**建構**: 中等 `<br>`**查詢**: 低到中等 `<br>`**記憶體**: 可配置                   |

---

## 🎯 Cross-encoder 重排序 (Reranking)

Cross-encoder 重排序是 RAG 檢索流程中的關鍵「精煉」步驟，位於檢索流程的第二階段精排階段，在「召回」階段之後對候選文件進行再次審閱和精細排序。這個過程就像招聘面試：第一階段召回如 HR 海選出 100 位候選人，而 Rerank 則是技術主管進行深度面試，從中挑出最頂尖的 3-5 位。

Cross-encoder 重排序要解決的核心問題源於傳統檢索方法的限制。我們用於檢索的 Embedding 模型（稱為 Bi-encoder）是將「查詢」和「文件」分開編碼成向量，再比較其相似度，這樣做速度很快，適合大規模海選。但這種「分開比較」的方式，無法捕捉到查詢和文件之間細微的、交互的語義關聯。Cross-encoder 的目的，就是用一種更精確、但更慢的方式，來彌補這個缺陷。

在運作原理方面，Cross-encoder 首先接收來自第一階段召回的 Top-K 個候選文件（例如 K=100）。接著進行成對精算，Cross-encoder 會將「查詢」和「每一個候選文件」成對地同時送入一個更強大的 Transformer 模型中。這個專門的機器學習模型作為「裁判」，評分基準是「使用者原始查詢」與「每一個候選文件」之間的「語意相關性」，為每個「查詢-文件」組合輸出精確的相關性分數（通常是 0 到 1 之間）。最後根據這個分數進行重新排序，挑出分數最高的 Top-N 個作為最終檢索結果。

Cross-encoder 重排序的優點是精確率極高，被公認為提升檢索結果相關性的「黃金標準」。缺點則是速度極慢、運算成本極高，因為需要對每個「查詢-文件對」都進行完整的模型推理，計算成本與候選集大小成正比，且無法預先建立索引。

### Reranker工具

Reranker工具主要分為三大類，各有不同的優勢和適用場景。**開源Cross-Encoder模型**將查詢和文件成對送入Transformer模型進行深度交互比對，是學術界公認效果最好的方法，適合對準確性要求極高且有技術團隊維護的場景。**商業Rerank API**（如Cohere Rerank）提供打包好的服務，無需管理硬體和模型，適合快速部署和中小型應用。**LLM作為Reranker**是最靈活的新興方法，可透過Prompt Engineering實現複雜的排序邏輯和可解釋性，但成本最高。

選擇策略取決於你的優先考量：追求極致準確性且有技術能力選擇開源模型；需要快速部署且成本可控選擇商業API；需要複雜邏輯和高度定制化選擇LLM方案。

| 方案類型                    | 代表工具                                         | 核心優勢                                                     | 主要劣勢                                                 | 適用場景                                                     |
| --------------------------- | ------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| **開源Cross-Encoder** | bge-reranker-large `<br>`sentence-transformers | 準確率最高 `<br>`完全控制與隱私保護 `<br>`深度交互式計算 | 需要GPU資源 `<br>`部署管理複雜 `<br>`運算成本高      | 對準確性要求極高 `<br>`有技術團隊維護 `<br>`隱私要求嚴格 |
| **商業Rerank API**    | Cohere Rerank `<br>`Jina AI `<br>`Voyage AI  | 方便易用 `<br>`高效能優化 `<br>`無需硬體管理             | 按次計費成本 `<br>`資料隱私風險 `<br>`依賴第三方服務 | 快速部署需求 `<br>`中小型應用 `<br>`成本可控範圍         |
| **LLM作為Reranker**   | GPT-4 `<br>`Claude 3 `<br>`Llama 3           | 極高靈活性 `<br>`可解釋性強 `<br>`複雜邏輯支持           | 成本最高 `<br>`延遲最長 `<br>`輸出格式不穩定         | 需要複雜排序邏輯 `<br>`高度定制化需求 `<br>`可解釋性重要 |

### Ranking方法的干預與訓練

讓RAG系統具備領域專家知識的關鍵在於客製化Reranker。**Prompt Engineering干預**適用於LLM Reranker，透過在提示中加入加權指令或排序偏好來快速調整排序邏輯。**Fine-tuning訓練**適用於開源Cross-Encoder模型，通過人工標註的三元組數據集讓通用模型學習特定領域的語義差別。

* **範例Prompt加權**: `"除了內容相關性，如果文件來源是『法務部』，其分數權重應乘以 1.2。如果文件標題包含『最終版』，其分數權重應乘以 1.5。"`
* **範例三元組數據**: `{ "query": "關於量子電池的過熱問題", "positive_passage": "文件A段落，詳細描述了電池散熱的解決方案", "negative_passage": "文件B段落，只提到了量子電池的優點，但沒提過熱問題" }`

**建議策略**: 起步選擇預訓練Cross-Encoder或商業API，需要複雜邏輯時嘗試LLM Reranker，追求極致準確度則投資微調專屬模型。

---

## ⚙️ 組合應用策略與最佳實踐

在真實的生產環境中，我們很少只單獨使用一種策略，而是會像搭積木一樣，將不同的技術組合起來，以應對複雜的需求。一個完整的檢索策略包含三個階段：檢索前的預過濾、檢索時的組合應用，以及檢索後的重排序精煉。

### 檢索前：預過濾策略 (Pre-filtering)

這是**所有生產級系統都必須採用的黃金組合**。在執行耗費資源的 ANN 向量搜索之前，先用精確的**元數據 (Metadata)** 進行過濾。能極大地提升查詢速度和準確性，同時降低運算成本。它確保了召回的結果不僅語意相關，而且完全符合使用者的確定性要求。一個查詢進來，系統會先執行 `WHERE` 子句（例如 `category = '法律' AND year > 2024`），將搜索範圍從千萬級的向量縮小到幾千級，**然後**才在這幾千個向量上執行 `HNSW` 或 `IVFFlat` 搜索。

### 檢索時：組合應用的方式 (Hybrid Strategies)

在檢索階段，我們可以採用多種組合策略來最佳化不同需求下的效能表現。

#### IVF + HNSW (混合索引)

一些先進的向量資料庫（如 Milvus）採用的兩層索引策略，結合了兩者的優點。先用 IVF 的思想，將數十億的龐大向量集，粗略地劃分成數千個分區 (partitions)。在**每一個**較小的分區內部，再使用 HNSW 來組織向量。解決了單一 HNSW 圖索引在超大規模（數十億級）下可能導致記憶體爆炸的問題。查詢時，先快速定位到少數幾個分區，然後在這些分區內進行極速的 HNSW 搜索。這是在**極致規模**下，兼顧記憶體、速度和準確性的高效方案。

#### 混合式搜尋 (Hybrid Search: vDB + BM25)

單純的向量搜索（vDB）雖然能理解語意，但對「**關鍵字**」非常不敏感。例如，使用者查詢「`PostgreSQL v15.3` 的 bug」，向量搜索可能會找回很多關於「資料庫效能問題」或「PostgreSQL 新功能」的文件，卻可能漏掉標題就是「Report: Bug in `PostgreSQL v15.3`」的關鍵文件。另一方面，傳統的關鍵字搜索（以 `BM25` 演算法為代表）能精準匹配「`PostgreSQL`」和「`v15.3`」這兩個詞，但完全無法理解「資料庫效能問題」和「database performance issue」是同一個意思。**Hybrid Search 的目的，就是結合兩者之長**。既不錯過任何包含精確關鍵字的「字面相關」文件，也不放過任何與查詢意義相近的「語意相關」文件。

當使用者提出一個查詢時，系統會**同時**將該查詢發送到兩個不同的搜索引擎：一個是**向量資料庫 (vDB)**，進行向量相似度搜索；另一個是基於**BM25 的全文檢索引擎**（例如 Elasticsearch 或某些 vDB 的內建功能），進行關鍵字搜索。系統會得到兩個不同的、帶有各自評分的排序列表。接著，它會用一種融合演算法（最常用的是**Reciprocal Rank Fusion, RRF**），將這兩個列表合併成一個更全面的排序結果，作為第一階段的召回成果。

混合式搜索的召回率極高，大幅減少了「漏網之魚」，系統變得更加穩健，不易被特定類型的查詢問倒；兼顧關鍵字與語意，對使用者更友好，無論是輸入精確的產品型號，還是模糊的描述性問題，都能給出不錯的初步結果。然而其架構複雜度增加，你需要維護兩套索引系統（向量索引和關鍵字索引）；需要融合策略，如何融合兩個來源的排序結果，本身就是一個需要調校的技術點；初步結果可能仍有雜訊，因為是廣撒網，所以召回的候選集（例如 Top 100）中，相關文件的「純度」可能不是最高的。

### 檢索後：重排序精煉 (ANN + Re-ranker)

這是追求**極致準確率**時採用的檢索策略。其完美結合了 向量檢索的**速度**和 Re-ranker 的**精度**。這是當前許多頂級 RAG 系統提升答案品質的秘密武器。

**第一階段 - 召回 (Recall)**：使用一個速度飛快的 ANN 索引（例如，`HNSW` 並將 `ef_search` 設得較低），快速地從海量資料中召回一個相對較大的候選集（例如 Top 50-100 個結果）。這個階段的目標是「寧可錯殺，不可放過」。

**第二階段 - 精排 (Precision)**：將這 100 個候選結果，交給一個更強大、但運算更慢的「**重排序模型 (Re-ranker)**」（通常是 Cross-Encoder 模型）。這個模型會將使用者的查詢和每一個候選文件的內容進行深度比較和打分，最後篩選出最精準的 Top 3-5 個結果。

**效果**：

### 最佳實踐：完整檢索架構

在 SOTA RAG 系統中，我們將三個階段串聯：預過濾縮小搜索範圍 → Hybrid Search 召回 Top 100 候選文件 → Cross-encoder Reranker 精排出 Top 3-5 → LLM 生成答案。這個四步流程既保證召回全面性，又確保最終上下文的極致精準。實際應用時，建議從 HNSW 開始並必須結合預過濾；遇到記憶體瓶頸選 IVFFlat，準確率瓶頸加重排序，規模瓶頸用 IVF+HNSW 混合索引。最佳索引策略源於對資料分布、查詢模式和業務需求的深刻理解。

## 🚀 優化召回

### 🧠 上下文感知檢索 (Context-aware Retrieval)

上下文感知檢索是指在檢索到相關分塊後，不直接使用這些分散的片段，而是利用metadata回溯到分塊所屬的完整文件或頁面單位，進行去重和重新排序，最終以更完整的上下文單位進行答案生成的檢索策略。

傳統RAG因為分塊可能將相關內容切割到不同chunk中，導致生成時缺乏完整語境。上下文感知檢索通過「先找片段，再拿整頁」的方式，確保LLM獲得充足的上下文來理解和回答問題。這正是為了解決標準RAG因為「分塊」而導致的「**上下文碎片化 (Context Fragmentation)**」問題的進階作法。

**核心流程轉變**：

- **標準RAG**：檢索(Chunk) → 排序(Chunk) → 生成
- **上下文感知檢索**：檢索(Chunk) → 擴展(Document/Page) → 去重 → 排序(Document/Page) → 生成

上下文感知檢索的最大優勢在於提供**完整上下文**，讓LLM獲得完整頁面而非孤立片段，從而生成更連貫的答案。這種方法特別適合處理**複雜問題**，尤其是答案分散在文件不同部分的綜合性問題。此外，Cross-encoder基於完整頁面進行相關性判斷時會更加**精確**，因為有更多上下文線索可供參考。

然而，這種策略也帶來明顯的代價。首先是**延遲增加**，系統需要額外的內容回取步驟，增加I/O操作時間。更嚴重的是**成本大增**問題，LLM處理的token數量可能增加8-10倍，導致API費用成倍增長。同時存在**黃金段落稀釋風險**，頁面中的噪音內容可能分散LLM注意力，反而降低答案品質。最後，整體**架構變得複雜**，需要同時維護向量資料庫和文件儲存庫兩套系統。

#### 實現架構與成本優化

技術架構需要向量資料庫（如Pinecone、pgvector）儲存帶有清晰metadata的分塊，文件儲存庫（S3、Redis或現有資料庫）快速回取原始內容，以及統籌器（LangChain、LlamaIndex）編排整個工作流程。

**統籌器的核心任務**是建立高效的快取層，在統籌器和文件儲存庫之間加入Redis等快取系統，避免重複的I/O操作。同時實現**彈性上下文策略**，根據文件長度選擇滑動窗口上下文（取回關鍵分塊前後各一個分塊）或摘要取代全文（用高速LLM先摘要再處理），在提供上下文的同時控制token數量。

然而，最關鍵的成本控制策略是**智慧化分級處理**。這是一種自適應RAG策略，系統先判斷問題複雜度：簡單問題走標準分塊RAG流程，只有複雜問題才觸發昂貴的上下文擴展重排序流程。這種分級處理將上下文感知檢索定位為RAG系統武器庫中的「攻城重砲」，只在最需要深度理解的查詢時使用，實現答案品質與系統成本的最佳平衡。

### 🔗 多資料庫共同工作

企業應用場景中常需要整合多種資料來源，這包括語義差別大的多個向量資料庫，以及傳統關聯式資料庫與向量資料庫的混合使用。

#### 聯邦式 RAG (Federated RAG)

多個語意差別大的向量資料庫（法律、銷售、圖片、影音等）組成的聯邦式 RAG 系統，需要整合多種異質性資料來源形成企業級知識中心。在這種複雜的多資料庫環境下，提升召回率和精準度需要設計更高層次的「智慧檢索統籌器 (Intelligent Retrieval Orchestrator)」。

最大的挑戰在於：如何在不遺漏跨領域洞見（高召回率）的前提下，快速定位到最相關的資訊源，並將來自不同源頭的結果，融合成一個準確、一致的答案（高精準度）。

**智慧檢索統籌器架構**：就像一個聰明的圖書管理員，當你問問題時，它會：1) 先判斷要去哪幾個資料庫找資料，2) 同時去多個地方搜尋，3) 把找到的結果按排名合併，4) 最後用統一標準重新排序。前提是所有資料庫都要用相同的「語言」（Embedding模型）才能比較。

#### 混合資料庫架構 (Polyglot Persistence)

向量資料庫並不適用所有場景。高度結構化、數字精確、且依賴關鍵字查詢的資料（如進銷存、財務報表、使用者帳戶）使用關聯性資料庫或NoSQL表現更好，且不需要耗費LLM的token。核心原則是「**多樣化持續性 (Polyglot Persistence)**」——為不同類型的工作選擇最適合的資料庫。

要將不同資料（適合語義的放在向量資料庫、結構化的放在關聯性資料庫）在檢索階段一起抓到並分析，需要將RAG系統從「檢索器」升級為「**智慧型數據代理 (Intelligent Data Agent)**」。

**數據代理架構**：像一個聰明的助理，聽到你的問題後，會先把複雜問題拆解成小任務，識別哪些任務需要精確數字（用傳統資料庫），哪些需要語意理解（用向量資料庫），然後分別去執行，最後把結果整合成完整答案。

關鍵在於**問題分解**：系統要能判斷「銷售量」這種精確數字問題該用SQL查傳統資料庫，「客戶評價」這種語意問題該用向量搜索，然後將一個問題智慧地拆分成適合不同資料庫的子問題，分頭進行後再統一整合。這讓AI從單純的文字處理器升級為能操作各種資料庫的數位助理。

#### 資料庫使用說明書撰寫

與其讓LLM代理去「猜測」每個資料庫裡有什麼，不如主動地、明確地告訴它——為資料庫提供清晰的「**使用說明書**」。在Agentic RAG架構中，這份「說明書」就是定義「工具 (Tool)」時所附帶的「描述 (Description)」。

**簡單來說就是寫使用手冊**：在使用LangChain或LlamaIndex等Agent框架時，每個資料庫都要定義成一個「工具(Tool)」，然後在工具的描述欄位裡寫清楚這個資料庫是幹什麼用的。

**傳統資料庫工具描述範例**：
「此工具用於查詢公司的ERP系統，當問題涉及具體的銷售數字、庫存水位、產品價格或訂單狀態時，應優先使用此工具。」

**向量資料庫工具描述範例**：

- **法律文件向量庫**：`search_legal_documents` - 搜索合約、法務備忘錄、合規性報告等
- **銷售市場向量庫**：`search_marketing_materials` - 搜索產品白皮書、客戶案例、市場分析等
- **圖片向量庫**：`search_images` - 搜索產品照片、活動照片、設計圖稿等

**代理總提示範例**：

```
你是一位萬能的企業分析助理。可用工具列表：
1. query_erp_database(sql_query: str) - 查詢銷售、庫存等精確業務數據
2. search_legal_documents(query: str) - 搜索法律合約與合規文件
3. search_marketing_materials(query: str) - 搜索產品介紹與市場分析
4. search_images(query: str) - 根據描述搜索圖片

任務指示：根據使用者問題，思考需要哪些資訊，選擇最適合的工具獲取資訊，最後整合所有資訊給出全面準確答案。
```

這樣AI就知道什麼時候該用哪個資料庫，不用自己瞎猜。
