# LLM 的真實面貌：從神話到現實

## 媒體炒作 vs 技術現實

天天媒體就是AI要取代誰誰誰了，大語言模型（LLM）真的有這麼神？

其實不然。LLM終究是依照大量既有資料，按照規律連續生成的系統，它還有很多無法逾越的開發問題。（2025/8）

## 楊立昆的觀點：AGI 的四大挑戰

前陣子Meta楊立昆（Yann LeCun）說對於LLM再繼續進化已無興趣，AI往AGI的四個繼續探索方向應該是：

1. 讓AI理解物理世界
2. 讓它們擁有記憶
3. 有推理能力
4. 有規劃能力

確實現在大家都在AI Agent上卷，卷得還是大模型本身。

## 四大挑戰的深度分析

### 1. 理解物理世界

楊立昆他們自己的做法在虛擬世界搭建空間。也還有Google為主的在往多模態的空間辨識、統計去努力。

但我感覺終究現在AI還被困在電腦前，無論是家具、機器人還是其他每天能與物理世界接觸的載具還太少，連深度相機目前都還僅僅是pro級的iPhone和iPad常備。一旦這些普及起來，理解物理世界可能是分分鐘的事。物理常識也是同理。

### 2. 擁有記憶

從應用層面來說是現在大眾最需要AI達到的，不論是訓練助手還是客服、不論是要更新和自行學習，都需要記憶。最基礎的，在一個網頁端對話框與LLM對話，它過一陣子都會接不上，這就很尷尬。

人類的記憶若不經過訓練其實是沒什麼邏輯的，每件事、知識像是打了tag一樣儲存在記憶宮殿各處並且建立關聯（Obsidian想要輔助人類記憶、知識整理也是基於這個原理），然後我們調取這些記憶的時候又可以抽象或模糊比對。

現在知識庫系統RAG建立的向量資料庫雖然走的也是這個概念，但是若不是在寫入系統的時候提供好各種調取的鉤子，匹配效率太差。再不要說長期記憶、短期記憶，優先重要、情感驅動或五感驅動的記憶，太複雜了。如果AI真的能擬態這些，完全已經有人格了吧XD。

退而求其次，如果能按照人訂標準去分類儲藏是否能在近未來完成客服等高頻需求的工作呢？

### 3. 推理能力

雖然這半年以來各家LLM的DeepThink、DeepSearch、DeepResearch已經能夠生成看似經過"邏輯思考"而達成的報告，但其實它還是在應用LLM底層的總結以及基於規則的符號推理。再加上搜索、爬蟲閱讀之後利用大量數據和文章去仿造出推理的機能。

但這距離人類基於高度抽象的條件去判斷以及通過既有知識去類比或通過常識判斷都還有距離。

### 4. 規劃能力

其實這與前兩天我在思考如果要為無電腦能力的人去規劃n8n workflow的時候，應該從結論開始一步步往前推的結果導向做法相似。就比如我簡略的需求思維圖要請LLM去製作n8n workflow它的過程一定不完全如人意一樣。

現今的LLM對於結果導向、目標導向還無法理解，那也就很難協助規劃事情。大多的規劃又是建立與學習的總結上，而不是通過現狀目標去執行判斷。目前各家研究的發展方向有往行動序列和按照大量學習總結以預測行動後果等。

## 人類發展的層次對照

我覺得很有趣因為這幾點是作為一個人類的層層遞進：

1. **物理世界理解**：我們出生長大自然會理解一些基礎常識物理，能夠明白我們身處位置與空間中的關係，感受風、光、眼睛辨識物體透視的形變等等。
2. **記憶系統**：接下來我們擁有各自風格的記憶系統、記憶能力，但又都至少具備長期記憶和短期記憶，這些記憶又都有一條以自我為貫穿的中軸線。
3. **高級認知**：然後才是推理和規劃，這即便作為一個人類，都是比較高級的"功能"了，擁有的人才是少數吧。

## 結語

LLM確實帶來了革命性的改變，但離真正的AGI還有很長的路要走。理解這些限制，反而能讓我們更好地利用現有的AI工具，在它們擅長的領域發揮最大價值，而不是盲目期待它們無所不能。
